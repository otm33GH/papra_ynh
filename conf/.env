# The application version. Set via PAPRA_VERSION build arg in Docker.
PAPRA_VERSION=prod

# The git commit hash. Set via GIT_COMMIT build arg in Docker.
# GIT_COMMIT=unknown

# The git commit date (ISO 8601 format). Set via BUILD_DATE build arg in
# Docker.
# BUILD_DATE=unknown

# The process mode: "all" runs both web and worker, "web" runs only the API
# server, "worker" runs only background tasks.
# PROCESS_MODE=all

# The base URL of the application. Will override the client baseUrl and
# server baseUrl when set. Use this one over the client and server baseUrl
# when the server is serving the client assets (like in docker).
APP_BASE_URL=https://__DOMAIN__

# The URL of the client, when using docker, prefer using the `APP_BASE_URL`
# environment variable instead.
# CLIENT_BASE_URL=http://localhost:1221

# The base URL of the server, when using docker, prefer using the
# `APP_BASE_URL` environment variable instead.
# SERVER_BASE_URL=http://localhost:1221

# A comma separated list of origins that are trusted to make requests to the
# server. The client baseUrl (CLIENT_BASE_URL) is automatically added by
# default, no need to add it to the list.
# TRUSTED_ORIGINS=

# A comma separated list of app schemes that are trusted for authentication.
# For example: "papra://,exp://". Note, setting this value will override the
# default schemes, so make sure to include them if needed.
# TRUSTED_APP_SCHEMES=papra://,exp://

# The port to listen on when using node server.
PORT=__PORT__

# The hostname to bind to when using node server.
# SERVER_HOSTNAME=0.0.0.0

# The maximum time in milliseconds for a route to complete before timing out.
# SERVER_API_ROUTES_TIMEOUT_MS=20000

# Route-specific timeout overrides. Allows setting different timeouts for
# specific HTTP method and route paths.
# undefined=[object Object]

# The CORS origin for the api server.
# SERVER_CORS_ORIGINS=http://localhost:3000

# Whether to serve the public directory (default as true when using docker).
# SERVER_SERVE_PUBLIC_DIR=false

# The URL of the database (default as "file:./app-data/db/db.sqlite" when
# using docker).
# DATABASE_URL=

# The auth token for the database.
# DATABASE_AUTH_TOKEN=

# The encryption key for the database. If not provided, the database will not
# be encrypted at rest. Use with caution as if lost, the data will be
# unrecoverable.
# DATABASE_ENCRYPTION_KEY=

# The retention period in days for deleted documents.
DOCUMENTS_DELETED_DOCUMENTS_RETENTION_DAYS=__RETENTION__

# The languages codes to use for OCR, multiple languages can be specified by
# separating them with a comma. See
# https://tesseract-ocr.github.io/tessdoc/Data-Files#data-files-for-version-400-november-29-2016.
DOCUMENTS_OCR_LANGUAGES=__LANGUAGE__

# The maximum size in bytes for an uploaded file. Set to 0 to disable the
# limit and allow uploading documents of any size.
DOCUMENT_STORAGE_MAX_UPLOAD_SIZE=__MAX_UP__

# The driver to use for document storage, values can be one of: `filesystem`,
# `s3`, `in-memory`, `azure-blob`.
DOCUMENT_STORAGE_DRIVER=__DOC_STORAGE_DRIVER__

# Whether to enable content extraction (OCR and text extraction) for uploaded
# documents.
DOCUMENTS_CONTENT_EXTRACTION_ENABLED=true

# The root directory to store documents in (default as "./app-data/documents"
# when using docker).
DOCUMENT_STORAGE_FILESYSTEM_ROOT=__DATA_DIR__

# The AWS access key ID for S3.
DOCUMENT_STORAGE_S3_ACCESS_KEY_ID=

# The AWS secret access key for S3.
DOCUMENT_STORAGE_S3_SECRET_ACCESS_KEY=

# The S3 bucket name.
DOCUMENT_STORAGE_S3_BUCKET_NAME=

# The AWS region for S3.
DOCUMENT_STORAGE_S3_REGION=auto

# The S3 endpoint.
DOCUMENT_STORAGE_S3_ENDPOINT=

# Whether to force path style URLs for S3.
DOCUMENT_STORAGE_S3_FORCE_PATH_STYLE=true

# The Azure Blob Storage connection string, if provided, the other account
# name, account key and container name will be ignored.
DOCUMENT_STORAGE_AZURE_BLOB_CONNECTION_STRING=

# The Azure Blob Storage account name.
DOCUMENT_STORAGE_AZURE_BLOB_ACCOUNT_NAME=

# The Azure Blob Storage account key.
DOCUMENT_STORAGE_AZURE_BLOB_ACCOUNT_KEY=

# The Azure Blob Storage container name.
DOCUMENT_STORAGE_AZURE_BLOB_CONTAINER_NAME=

# Whether to enable encryption for documents.
# DOCUMENT_STORAGE_ENCRYPTION_IS_ENABLED=false

# Key encryption keys (KEKs) used to encrypt the document encryption key
# (DEK), as 32-byte hex strings, you can generate one using the command
# `openssl rand -hex 32`.

#Â Formats:
#- Single key:
# `0deba5534bd70548de92d1fd4ae37cf901cca3dc20589b7e022ddb680c98e50c` (will be
# assigned version `1`)
#- Multiple keys: `1:<key1>,2:<key2>`
#   - The key
# with the highest version will be used to encrypt new DEKs, others will be
# used to decrypt existing DEKs
#   - Versions must be unique and can be any
# alphabetically sortable string
#   - The order of the version:key pair is
# not important.
# DOCUMENT_STORAGE_DOCUMENT_KEY_ENCRYPTION_KEYS=

# The document search provider to use, values can be one of: `database-fts5`.
# DOCUMENT_SEARCH_DRIVER=database-fts5

# The secret for the auth, it should be at least 32 characters long, you can
# generate a secure one using `openssl rand -hex 48`.
AUTH_SECRET=__AUTH_SECRET__

# Whether registration is enabled.
AUTH_IS_REGISTRATION_ENABLED=__REGISTRATION__

# Whether password reset is enabled.
AUTH_IS_PASSWORD_RESET_ENABLED=__PWD_RESET__

# Whether email verification is required.
AUTH_IS_EMAIL_VERIFICATION_REQUIRED=__EMAIL_VERIFICATION__

# Whether to show Papra legal links on the auth pages (terms of service,
# privacy policy), useless for self-hosted instances.
# AUTH_SHOW_LEGAL_LINKS=false

# Automatically assign the admin role to the first user who registers. This
# is useful for initial setup of self-hosted instances where you need an
# admin account to manage the platform.
# AUTH_FIRST_USER_AS_ADMIN=true

# The header, or comma separated list of headers, to use to get the real IP
# address of the user, use for rate limiting. Make sur to use a non-spoofable
# header, one set by your proxy.
#- If behind a standard proxy, you might want
# to set this to "x-forwarded-for".
#- If behind Cloudflare, you might want to
# set this to "cf-connecting-ip".
# AUTH_IP_ADDRESS_HEADERS=x-forwarded-for

# A comma separated list of email domains that are forbidden for registration
# (e.g. "foo.com,bar.com"), if set, it will override the default forbidden
# domains.
# AUTH_FORBIDDEN_EMAIL_DOMAINS=papra.app,papra.email,owlrelay.email,callback.email,clb.email

# Whether email/password authentication is enabled.
# AUTH_PROVIDERS_EMAIL_IS_ENABLED=true

# Whether Github OAuth is enabled.
# AUTH_PROVIDERS_GITHUB_IS_ENABLED=false

# The client id for Github OAuth.
# AUTH_PROVIDERS_GITHUB_CLIENT_ID=set-me

# The client secret for Github OAuth.
# AUTH_PROVIDERS_GITHUB_CLIENT_SECRET=set-me

# Whether Google OAuth is enabled.
# AUTH_PROVIDERS_GOOGLE_IS_ENABLED=false

# The client id for Google OAuth.
# AUTH_PROVIDERS_GOOGLE_CLIENT_ID=set-me

# The client secret for Google OAuth.
# AUTH_PROVIDERS_GOOGLE_CLIENT_SECRET=set-me

# The list of custom OAuth providers, as a JSON string, see
# https://www.better-auth.com/docs/plugins/generic-oauth#configuration for
# more details.
# AUTH_PROVIDERS_CUSTOMS=

# Whether ingestion folders are enabled.
# INGESTION_FOLDER_IS_ENABLED=false

# The root directory in which ingestion folders for each organization are
# stored.
# INGESTION_FOLDER_ROOT_PATH=./ingestion

# Whether to use polling for the ingestion folder watcher.
# INGESTION_FOLDER_WATCHER_USE_POLLING=false

# When polling is used, this is the interval at which the watcher checks for
# changes in the ingestion folder (in milliseconds).
# INGESTION_FOLDER_WATCHER_POLLING_INTERVAL_MS=2000

# The number of files that can be processed concurrently by the server.
# Increasing this can improve processing speed, but it will also increase CPU
# and memory usage.
# INGESTION_FOLDER_PROCESSING_CONCURRENCY=1

# The folder to move the file when the ingestion fails, the path is relative
# to the organization ingestion folder (<ingestion root>/<organization id>).
# INGESTION_FOLDER_ERROR_FOLDER_PATH=./ingestion-error

# The action done on the file after it has been ingested.
# INGESTION_FOLDER_POST_PROCESSING_STRATEGY=delete

# The folder to move the file when the post-processing strategy is "move",
# the path is relative to the organization ingestion folder (<ingestion
# root>/<organization id>).
# INGESTION_FOLDER_POST_PROCESSING_MOVE_FOLDER_PATH=./ingestion-done

# Comma separated list of patterns to ignore when watching the ingestion
# folder. Note that if you update this variable, it'll override the default
# patterns, not merge them. Regarding the format and syntax, please refer to
# the [picomatch
# documentation](https://github.com/micromatch/picomatch/blob/bf6a33bd3db990edfbfd20b3b160eed926cd07dd/README.md#globbing-features).
# INGESTION_FOLDER_IGNORED_PATTERNS=**/.DS_Store,**/.env,**/desktop.ini,**/Thumbs.db,**/.git/**,**/.idea/**,**/.vscode/**,**/node_modules/**,**/@eaDir/**,**/*@SynoResource,**/*@SynoEAStream

# The driver to use for the tasks persistence, values can be one of:
# `memory`, `libsql`. Using the memory driver is enough when running a single
# instance of the server.
# TASKS_PERSISTENCE_DRIVER=memory

# The URL of the LibSQL database, can be either a file-protocol url with a
# local path or a remote LibSQL database URL.
# TASKS_PERSISTENCE_DRIVERS_LIBSQL_URL=file:./tasks-db.sqlite

# The auth token for the LibSQL database.
# TASKS_PERSISTENCE_DRIVERS_LIBSQL_AUTH_TOKEN=

# Whether to include the PRAGMA statements when setting up the LibSQL
# database schema.
# TASKS_PERSISTENCE_DRIVERS_LIBSQL_MIGRATE_WITH_PRAGMA=true

# The interval at which the task persistence driver polls for new tasks.
# TASKS_PERSISTENCE_DRIVERS_LIBSQL_POLL_INTERVAL_MS=1000

# The id of the task worker, used to identify the worker in the Cadence
# cluster in case of multiple workers, should be unique per instance.
# TASKS_WORKER_ID=

# The cron schedule for the task to hard delete expired "soft deleted"
# documents.
# DOCUMENTS_HARD_DELETE_EXPIRED_DOCUMENTS_CRON=0 0 * * *

# Whether the task to hard delete expired "soft deleted" documents should run
# on startup.
# DOCUMENTS_HARD_DELETE_EXPIRED_DOCUMENTS_RUN_ON_STARTUP=true

# The cron schedule for the task to expire invitations.
# ORGANIZATIONS_EXPIRE_INVITATIONS_CRON=0 0 * * *

# Whether the task to expire invitations should run on startup.
# ORGANIZATIONS_EXPIRE_INVITATIONS_RUN_ON_STARTUP=true

# The cron schedule for the task to purge expired soft-deleted organizations.
# ORGANIZATIONS_PURGE_EXPIRED_ORGANIZATIONS_CRON=0 1 * * *

# Whether the task to purge expired soft-deleted organizations should run on
# startup.
# ORGANIZATIONS_PURGE_EXPIRED_ORGANIZATIONS_RUN_ON_STARTUP=true

# Whether intake emails are enabled.
# INTAKE_EMAILS_IS_ENABLED=false

# The secret to use when verifying webhooks, should be a random string
# between 16 and 128 characters.
# INTAKE_EMAILS_WEBHOOK_SECRET=please-change-me

# The driver to use when generating email addresses for intake emails, value
# can be one of: `owlrelay`, `catch-all`.
# INTAKE_EMAILS_DRIVER=catch-all

# The API key used to interact with OwlRelay for the intake emails.
# OWLRELAY_API_KEY=change-me

# The webhook URL to use when generating email addresses for intake emails
# with OwlRelay, if not provided, the webhook will be inferred from the
# server URL.
# OWLRELAY_WEBHOOK_URL=

# The domain to use when generating email addresses for intake emails with
# OwlRelay, if not provided, the OwlRelay will use their default domain.
# OWLRELAY_DOMAIN=

# The domain to use when generating email addresses for intake emails when
# using the `catch-all` driver.
# INTAKE_EMAILS_CATCH_ALL_DOMAIN=papra.local

# The driver to use when generating email addresses for intake emails, value
# can be one of: `random`, `pattern`.
# INTAKE_EMAILS_USERNAME_DRIVER=random

# The pattern to use when generating email addresses usernames (before the @)
# for intake emails. Available placeholders are: {{user.name}}, {{user.id}},
# {{user.email.username}}, {{organization.id}}, {{organization.name}},
# {{random.digits}}. Note: the resulting username will be slugified to remove
# special characters and spaces.
# INTAKE_EMAILS_USERNAME_DRIVER_PATTERN={{user.name}}-{{random.digits}}

# The email address to send emails from.
# EMAILS_FROM_ADDRESS=Papra <auth@mail.papra.app>

# The driver to use when sending emails, value can be one of: `resend`,
# `logger`, `smtp`. Using `logger` will not send anything but log them
# instead.
# EMAILS_DRIVER=logger

# The API key for the Resend email service.
# RESEND_API_KEY=

# When using the logger email driver, the level to log emails at.
# LOGGER_EMAIL_DRIVER_LOG_LEVEL=info

# The host of the SMTP server.
SMTP_HOST=__EMAIL_SMTP_HOST__

# The port of the SMTP server.
SMTP_PORT=__EMAIL_SMTP_PORT__

# The user of the SMTP server.
SMTP_USER=__EMAIL_SMTP_USER__

# The password of the SMTP server.
SMTP_PASSWORD="__EMAIL_SMTP_PASSWORD__"

# Whether to use a secure connection to the SMTP server.
SMTP_SECURE=true

# The raw configuration for the nodemailer SMTP client in JSON format for
# advanced use cases. If set, this will override all other config options.
# See https://nodemailer.com/smtp/ for more details.
# SMTP_JSON_CONFIG=

# The maximum number of organizations a standard user can have.
# MAX_ORGANIZATION_COUNT_PER_USER=10

# The number of days an invitation to an organization will be valid.
# ORGANIZATION_INVITATION_EXPIRATION_DELAY_DAYS=7

# The maximum number of invitations a user can send per day.
# MAX_USER_ORGANIZATIONS_INVITATIONS_PER_DAY=30

# The number of days before a soft-deleted organization is permanently
# purged.
# ORGANIZATIONS_DELETED_PURGE_DAYS_DELAY=30

# Whether the free plan is unlimited, meaning it has no limits on the number
# of documents, tags, and organizations, basically always true for
# self-hosted instances.
# IS_FREE_PLAN_UNLIMITED=true

# The Stripe coupon ID to apply globally for launch promotions.
# GLOBAL_COUPON_ID=

# The maximum number of tags an organization can have.
# MAX_TAGS_PER_ORGANIZATION=200

# Whether to enable PostHog.
# POSTHOG_ENABLED=false

# The API key for PostHog.
# POSTHOG_API_KEY=set-me

# The host for PostHog.
# POSTHOG_HOST=https://eu.i.posthog.com
